<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic - Editorial by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Editorial</strong> by HTML5 UP</a>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Virtual reality game for upper arm range of motion evaluation and rehabilitation using capability maps</h1>
									</header>

									<span class="image main"><img src="images/pic11.jpg" alt="" /></span>

									<p>Physical therapy interventions are essential for improving the range of motion (ROM) in individuals with upper arm impairments. However, traditional approaches often lack interactivity and fail to keep patients motivated, resulting in sub-optimal outcomes. To address this, I leveraged the power of virtual reality (VR) technology in healthcare. By combining VR with motion tracking technology, I developed an interactive game that provides users with a virtual environment to perform a variety of arm movements and exercises. This immersive and engaging experience enhances patient motivation and offers a promising tool for effective rehabilitation.</p>
									<p>The primary objectives of this research project were two-fold:</p>
									<ul>
										<li>To evaluate users' range of motion (ROM) in 3D space using capability maps.</li>
										<li>To utilize the information from these capability maps to create a virtual reality (VR) game that aids in upper arm rehabilitation.</li>
									</ul>
									<p>The VR game was designed to offer an engaging experience during repetitive exercises, thereby encouraging compliance and adherence to therapy.</p>
									<p>One of my key projects focuses on developing an engaging and personalized virtual reality (VR) game for ROM assessment and rehabilitation. The main goal is to provide individuals with an enjoyable and motivating experience while tracking their arm movements in real-time. The system generates capability maps that visually represent the individual's reachability and functional limitations, enhancing their rehabilitation journey.</p>
									<hr class="major" />

									<h2>How was it done?</h2>
									<h3>Kinematic modeling of the human arm</h3>
									<p>In my project, I needed to model the complexities of the human arm as a kinematic model. By simplifying it into a 7 degree-of-freedom (DoF) model, I was able to analyze its movements in a comprehensive manner. The shoulder complex, specifically the gleno-humeral joint, contributed 3 DoFs: abduction-adduction, flexion-extension, and internal-external rotation. The elbow joint involved flexion-extension and forearm pronation-supination, while the wrist encompassed ulnar-radial deviation, flexion-extension, and a shared degree of freedom with the elbow. By developing a rigid body tree model, I accurately represented the upper arm and forearm, incorporating volumetric collision meshes for precise collision detection.</p>
									
									<div style="display: flex;">
										<img src="images\Kinematic Models\Human Arm without Collision Mesh - 1 .png" alt="Human arm without Mesh" style="width: 50%;">
										<img src="images\Kinematic Models\Human Arm with Collision Mesh - 1.png" alt="Human arm with Mesh" style="width: 50%;">
									</div>

									<h3>Generation of capability maps for the human arm</h3>
									<p>I have explored the use of capability maps as a powerful tool for analyzing the workspace of a robotic arm. These maps provide insights into the reachability and limitations of the robot's end-effector in various positions and orientations.</p>
									<p>The generation of capability maps involves two primary methods. The first method utilizes inverse kinematics (IK) to determine the reachability of each bin within the workspace. By searching for valid joint values that correspond to the desired pose of the end-effector, reachable bins are marked. However, this approach comes with computational costs and may not always find a solution, even if one exists.</p>
									<p>The second method employs a forward kinematics (FK) approach, where random joint values are used to create transformation matrices, resulting in the end-effector's pose. Bins where the end-effector successfully reaches are marked as reachable. Although this method generates a larger number of samples, it does not guarantee a complete exploration of the robot's workspace.</p>
									<p>To achieve a more comprehensive capability map analysis, a hybrid approach combining FK and IK methods can be employed. This approach initially utilizes the faster exploration capabilities of FK. However, in cases where unique bins are challenging to find, the IK method is applied for a more precise analysis. This hybrid approach combines the speed and broader coverage of FK with the accuracy and completeness of IK, enhancing the capability map analysis for the robotic arm.</p>
									<p>In one of my key projects, I utilized capability maps as a visualization tool to assess an individual's range of motion and dexterity. I developed capability maps for both average healthy individuals and those with limited range of motion, allowing for a comparative analysis. By simulating restricted movement using braces, I documented the minimum and maximum range of motion for each degree of freedom in the arm.</p>
									<p>Using the hybrid approach, I developed capability maps for:</p>
									<ul>
										<li>Healthy individuals</li>
										<img src="images\Capability Maps\Healthy Capability Map.png" alt="Healthy Map" style="max-width: 100%; height: auto;">
										<li>Individuals with restricted shoulder</li>
										<img src="images\Capability Maps\Restricted Shoulder Capability Map.png" alt="Restricted Shoulder" style="max-width: 100%; height: auto;">
										<li>Individuals with restricted elbow</li>
										<img src="images\Capability Maps\Healthy Capability Map.png" alt="Healthy Map" style="max-width: 100%; height: auto;">
										<li>Individuals with restricted forearm</li>
										<img src="images\Capability Maps\Healthy Capability Map.png" alt="Healthy Map" style="max-width: 100%; height: auto;">
									</ul>

									
									<p>Additionally, I introduced a distinctive capability map called the "difference capability map." This map illustrates the disparities between the capability map of a healthy individual and those with limited range of motion. By visually depicting and analyzing the variations in range of motion and dexterity between the two groups, the difference capability map served as a valuable tool for identifying specific areas of limitations and challenges for individuals with reduced range of motion. These insights have contributed to the development of tailored rehabilitation strategies and interventions, enhancing our understanding of the impact of limited range of motion on joint functionality.</p>

									<img src="images\Capability Maps\Restricted Shoulder Difference Capability Map - 1.png" alt="Healthy Map" style="max-width: 100%; height: auto;">

									<h3>Development of the virtual reality game</h3>
									<p>I focused on real-time tracking of joint movements in a 3D space to create an immersive VR game. To achieve this, I utilized the Kinect v2 sensor, which tracked the pose of 25 joints in the human body at a rate of 30 frames per second. By integrating the Kinect sensor with the Unity game engine using the "Kinect v2 examples" SDK, I ensured accurate and up-to-date joint pose data. This data was crucial for transforming and updating the capability map based on the individual's movements.</p>
									<p>For precise hand tracking, I integrated the Leap Motion camera with the Kinect. While the Kinect tracked body joints, it lacked hand and finger tracking capabilities. By mounting the Leap Motion camera on the VR headset, I captured accurate hand movements. However, aligning the wrist joint tracking data between the two sensors posed a challenge. To overcome this, I adopted a hybrid approach. The Kinect was responsible for positional tracking of the wrist, providing accurate positioning information, while the Leap Motion camera handled rotation tracking, offering precise rotational data.</p>
									<p>To track head movements, I utilized the Kinect for position tracking in 3D space, while the VR headset's pose drivers were used to track head rotation. By combining the strengths of both sensors and assigning specific tracking responsibilities, I achieved synchronized and accurate tracking of joint movements, including hands and head, which greatly enhanced the overall gameplay experience.</p>
									<p>In terms of methodology, I developed a virtual reality (VR) game using Unity for upper arm range of motion (ROM) evaluation and rehabilitation. The game's core concept revolved around the use of capability maps to generate and manipulate virtual objects based on the user's position and reachability indexes.</p>
									<p>Within the VR environment, the capability maps were generated by analyzing the user's arm movements and limitations. Real-time arm motion tracking technology, such as the Kinect sensor, was employed to capture the user's movements. The captured data was processed and mapped onto a virtual representation of the user's arm within the game environment.</p>
									<p>Based on the capability maps, virtual objects were dynamically spawned in the game space. The position and reachability indexes derived from the capability maps determined the appropriate location and interaction possibilities of these virtual objects. This dynamic spawning of objects allowed for personalized rehabilitation exercises tailored to the individual's ROM and functional limitations.</p>
									<p>During gameplay, users were guided to interact repeatedly with each virtual object, simulating the repetitive movements typically performed in physical therapy. This approach aimed to replicate the therapeutic effect of repeated motions, which help improve the user's range of motion. The game provided real-time feedback on the user's performance, including metrics such as the range of motion. This feedback not only helped users track their progress but also facilitated the adaptation of the game's difficulty level and exercises based on their capabilities.</p>
									<hr class="major" />

									<h2>Magna etiam veroeros</h2>
									<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis dapibus rutrum facilisis. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Etiam tristique libero eu nibh porttitor fermentum. Nullam venenatis erat id vehicula viverra. Nunc ultrices eros ut ultricies condimentum. Mauris risus lacus, blandit sit amet venenatis non, bibendum vitae dolor. Nunc lorem mauris, fringilla in aliquam at, euismod in lectus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. In non lorem sit amet elit placerat maximus. Pellentesque aliquam maximus risus, vel sed vehicula.</p>
									<p>Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fersapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit tristique lorem ipsum dolor.</p>

									
								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">Homepage</a></li>
									<li><a href="generic.html">Generic</a></li>
									<li><a href="elements.html">Elements</a></li>
									<li>
										<span class="opener">Projects</span>
										<ul>
											<li><a href="Virtual reality game for upper arm range of motion evaluation and rehabilitation using Capability maps.html">Virtual reality game for upper arm range of motion evaluation and rehabilitation using Capability maps</a></li>
											<li><a href="One shot full body texture completion.html">One shot full body texture completion</a></li>
											<li><a href="Inverted pendulum simulation using Q-learning algorithm.html">Inverted pendulum simulation using Q-learning algorithm</a></li>
											<li><a href="Control of a 2D quadrotor using an iLQR algorithm.html">Control of a 2D quadrotor using an iLQR algorithm</a></li>
											<li><a href="Autonomous delivery robot.html">Control of a 2D quadrotor using an iLQR algorithm</a></li>
											<li><a href="#">Control of a 2D quadrotor using an iLQR algorithm</a></li>
											<li><a href="#">Control of a 2D quadrotor using an iLQR algorithm</a></li>
											<li><a href="#">Control of a 2D quadrotor using an iLQR algorithm</a></li>
										</ul>
									</li>
								</ul>
							</nav>

							

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Sed varius enim lorem ullamcorper dolore aliquam aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin sed aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">zw3374@nyu.edu</a></li>
										<li class="icon solid fa-phone">+1 551 229 2791</li>
										<li class="icon solid fa-home">Jersey City, New Jersey<br /></li>
									</ul>
								</section>

						

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>