<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic - Editorial by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Editorial</strong> by HTML5 UP</a>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Virtual reality game for upper arm range of motion evaluation and rehabilitation using capability maps</h1>
									</header>

									<span class="image main"><img src="images/pic11.jpg" alt="" /></span>

									<p style="text-align: justify;">Physical therapy interventions are <b>essential</b> for improving the <b>range of motion (ROM)</b> in individuals with <b>limited arm mobility</b>. However, traditional approaches often lack interactivity and fail to keep patients motivated, resulting in sub-optimal outcomes. To address this issue, the power of <b>virtual reality (VR)</b> technology was harnessed in the healthcare domain. By combining motion tracking technology with VR, an interactive game was developed, offering users a virtual environment for the performance of various arm movements and exercises. With an <b>immersive and engaging</b> experience, patient motivation is enhanced, presenting a promising tool for effective rehabilitation.</p>
									
									<p style="text-align: justify;">The research project had two primary objectives:</p>
									
									<ul>
										<li>The <b>evaluation</b> of users' range of motion (ROM) in 3D space using <b>capability maps</b>.</li>
										<li>The utilization of information from these <b>capability maps</b> to create a virtual reality (VR) game supporting upper arm rehabilitation.</li>
									</ul>
									
									<p style="text-align: justify;">The VR game was designed to provide an <b>engaging</b> experience during repetitive exercises, promoting <b>compliance</b> and <b>adherence</b> to therapy.</p>
									<p>A key project focuses on the development of an engaging and personalized <b>virtual reality (VR)</b> game for <b>ROM assessment</b> and <b>rehabilitation</b>. The primary goal is to offer individuals an enjoyable and motivating experience while their arm movements are <b>tracked in real-time</b>. The system generates <b>capability maps</b> that visually represent the reachability and functional limitations of the individual, <b>enhancing</b> their rehabilitation journey.</p>
									<hr class="major" />

									<h2>How was it done?</h2>
									<h3>Kinematic modeling of the human arm</h3>
									<p style="text-align: justify;">In the project, the complexities of the human arm were required to be modeled as a kinematic model. By simplifying it into a <b>7 degree-of-freedom (DoF)</b> model, a comprehensive analysis of its movements was made possible. The <b>gleno-humeral joint</b> within the <b>shoulder complex contributed 3 DoFs</b>, namely <b>abduction-adduction, flexion-extension, and internal-external rotation</b>. The <b>elbow joint</b> involved <b>flexion-extension</b> and <b>forearm pronation-supination</b>, while the <b>wrist</b> encompassed <b>ulnar-radial deviation, flexion-extension</b>, and a <b>shared degree of freedom with the elbow</b>. A <b>rigid body tree model</b> was developed to accurately represent the <b>upper arm and forearm</b>, incorporating volumetric collision meshes for precise <b>collision detection.</b></p>
									
									<div style="display: flex;">
										<img src="images\Kinematic Models\Human Arm without Collision Mesh - 1 .png" alt="Human arm without Mesh" style="width: 50%;">
										<img src="images\Kinematic Models\Human Arm with Collision Mesh - 1.png" alt="Human arm with Mesh" style="width: 50%;">
									</div>

									<h3>Generation of capability maps for the human arm</h3>
									
									<p style="text-align: justify;">The use of <b>capability maps</b> as a powerful tool for <b>analyzing the workspace</b> of a robotic arm has been explored. Insights into the reachability and limitations of the robot's end-effector in various positions and orientations are provided by these maps.</p>
									
									<p style="text-align: justify;">The generation of capability maps involves <b>two primary methods.</b> The reachability of each bin within the workspace is determined using <b>inverse kinematics (IK).</b> Reachable bins are marked by searching for valid joint values that correspond to the desired pose of the <b>end-effector.</b> However, a solution may not always be found, even if one exists, and computational costs are associated with this approach.</p>
									
									<p style="text-align: justify;">TA forward kinematics (FK) approach is used in the second method, where transformation matrices are created using random joint values to determine the pose of the end-effector. Reachable bins are marked based on successful end-effector reach. Although this method generates a larger number of samples, it does not guarantee a complete exploration of the robot's workspace.</p>
									
									<p style="text-align: justify;">To achieve a more comprehensive capability map analysis, a hybrid approach combining FK and IK methods can be employed. The faster exploration capabilities of FK are initially utilized, while the more precise analysis provided by the IK method is applied in cases where unique bins are challenging to find. This hybrid approach combines the speed and broader coverage of FK with the accuracy and completeness of IK, enhancing the capability map analysis for the robotic arm.</p>
									<p style="text-align: justify;">In one of the key projects, capability maps were utilized as a visualization tool to assess an individual's range of motion and dexterity. Capability maps were developed for both average healthy individuals and those with limited range of motion, enabling comparative analysis. The minimum and maximum range of motion for each degree of freedom in the arm were documented by simulating restricted movement using braces.</p>
									<p style="text-align: justify;">Using the hybrid approach, I developed capability maps for:</p>
									<ul>
										<li>Healthy individuals</li>
										<img src="images\Capability Maps\Healthy Capability Map.png" alt="Healthy Map" style="max-width: 100%; height: auto;">
										<li>Individuals with restricted shoulder</li>
										<img src="images\Capability Maps\Restricted Shoulder Capability Map.png" alt="Restricted Shoulder" style="max-width: 100%; height: auto;">
										<li>Individuals with restricted elbow</li>
										<img src="images\Capability Maps\Healthy Capability Map.png" alt="Healthy Map" style="max-width: 100%; height: auto;">
										<li>Individuals with restricted forearm</li>
										<img src="images\Capability Maps\Healthy Capability Map.png" alt="Healthy Map" style="max-width: 100%; height: auto;">
									</ul>

									
									<p style="text-align: justify;">Additionally, a distinctive capability map called the "difference capability map" was introduced. The "difference capability map" was utilized to illustrate the disparities between the capability map of a healthy individual and those with a limited range of motion. By visually depicting and analyzing the variations in range of motion and dexterity between the two groups, the difference capability map was utilized as a valuable tool for identifying specific areas of limitations and challenges for individuals with reduced range of motion. The development of tailored rehabilitation strategies and interventions has been enhanced through the insights provided by the difference capability map, contributing to our understanding of the impact of limited range of motion on joint functionality.</p>

									<img src="images\Capability Maps\Restricted Shoulder Difference Capability Map - 1.png" alt="Healthy Map" style="max-width: 100%; height: auto;">

									<h3>Development of the virtual reality game</h3>
									<p style="text-align: justify;">The real-time tracking of joint movements in a 3D space to create an immersive VR game was the main focus. The utilization of the Kinect v2 sensor, which tracked the pose of 25 joints in the human body at a rate of 30 frames per second, played a crucial role. Accurate and up-to-date joint pose data was ensured by integrating the Kinect sensor with the Unity game engine using the "Kinect v2 examples" SDK. The capability map was transformed and updated based on the individual's movements using this essential data.</p>

									<p style="text-align: justify;">For precise hand tracking, integration of the Leap Motion camera with the Kinect was performed. Hand and finger tracking capabilities were lacking in the Kinect, but accurate hand movements were captured by mounting the Leap Motion camera on the VR headset. Aligning the wrist joint tracking data between the two sensors posed a challenge, which led to the adoption of a hybrid approach. Positional tracking of the wrist was accomplished by the Kinect, providing accurate positioning information, while rotation tracking was handled by the Leap Motion camera, offering precise rotational data.</p>

									<p style="text-align: justify;">Head movements were tracked using the Kinect for position tracking in 3D space, while head rotation was tracked using the VR headset's pose drivers. The combination of both sensors and the assignment of specific tracking responsibilities resulted in synchronized and accurate tracking of joint movements, including hands and head, significantly enhancing the overall gameplay experience.</p>

									<p style="text-align: justify;">The methodology involved the development of a virtual reality (VR) game using Unity for the evaluation and rehabilitation of upper arm range of motion (ROM). The game's core concept revolved around the generation and manipulation of virtual objects based on the user's position and reachability indexes, achieved through the utilization of capability maps.</p>

									<p style="text-align: justify;">Within the VR environment, the capability maps were generated by analyzing the user's arm movements and limitations. Real-time arm motion tracking technology, such as the Kinect sensor, was employed for capturing the user's movements. The captured data was processed and mapped onto a virtual representation of the user's arm within the game environment.</p>

									<p style="text-align: justify;">Virtual objects were dynamically spawned in the game space based on the capability maps. The appropriate location and interaction possibilities of these virtual objects were determined using the position and reachability indexes derived from the capability maps. This dynamic spawning facilitated personalized rehabilitation exercises tailored to the individual's ROM and functional limitations.</p>

									<p style="text-align: justify;">During gameplay, users were guided to interact repeatedly with each virtual object, simulating the repetitive movements typically performed in physical therapy. This approach aimed to replicate the therapeutic effect of repeated motions, leading to an improvement in the user's range of motion. Real-time feedback, including metrics such as the range of motion, was provided to users, enabling them to track their progress. Additionally, the game's difficulty level and exercises could be adapted based on the user's capabilities.</p>

								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">Homepage</a></li>
									<li><a href="generic.html">Generic</a></li>
									<li><a href="elements.html">Elements</a></li>
									<li>
										<span class="opener">Projects</span>
										<ul>
											<li><a href="Virtual reality game for upper arm range of motion evaluation and rehabilitation using Capability maps.html">Virtual reality game for upper arm range of motion evaluation and rehabilitation using Capability maps</a></li>
											<li><a href="One shot full body texture completion.html">One shot full body texture completion</a></li>
											<li><a href="Ransac.html">Random sample consensus (RANSAC) </a></li>
											<li><a href="ICP.html">Iterative closest point (ICP)</a></li>
											<li><a href="FashionMNIST">Low dimension projection of the FashionMNIST dataset using TensorFlow </a></li>
											<li><a href="ORB.html">Feature extraction and matching </a></li>
											<li><a href="Inverted pendulum simulation using Q-learning algorithm.html">Inverted pendulum simulation using Q-learning algorithm</a></li>
											<li><a href="Control of a 2D quadrotor using an iLQR algorithm.html">Control of a 2D quadrotor using an iLQR algorithm</a></li>
											<li><a href="Autonomous delivery robot.html">Autonomous delivery robot</a></li>
											<li><a href="Sensor fusion">Sensor Fusion</a></li>
										</ul>
									</li>
								</ul>
							</nav>

							

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Sed varius enim lorem ullamcorper dolore aliquam aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin sed aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">zw3374@nyu.edu</a></li>
										<li class="icon solid fa-phone">+1 551 229 2791</li>
										<li class="icon solid fa-home">Jersey City, New Jersey<br /></li>
									</ul>
								</section>

						

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>